{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce8c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv, io, re, hashlib\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "    HAVE_BS4 = True\n",
    "except Exception:\n",
    "    HAVE_BS4 = False\n",
    "\n",
    "def sniff_delimiter(sample: str) -> str:\n",
    "    \"\"\"Very simple delimiter sniff: tab vs comma.\"\"\"\n",
    "    return \"\\t\" if sample.count(\"\\t\") > sample.count(\",\") else \",\"\n",
    "\n",
    "def html_to_text(html: str) -> str:\n",
    "    \"\"\"Convert HTML to plain text. Falls back if bs4 is missing.\"\"\"\n",
    "    if not html:\n",
    "        return \"\"\n",
    "    if HAVE_BS4:\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        text = soup.get_text(\"\\n\", strip=True)\n",
    "        text = re.sub(r\"[ \\t]+\\n\", \"\\n\", text)\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "        return text\n",
    "    # Fallback: crude stripping\n",
    "    text = re.sub(r\"<br\\s*/?>\", \"\\n\", html, flags=re.I)\n",
    "    text = re.sub(r\"</p\\s*>\", \"\\n\", text, flags=re.I)\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    text = text.replace(\"&nbsp;\", \" \").replace(\"&amp;\", \"&\")\n",
    "    text = re.sub(r\"[ \\t]+\\n\", \"\\n\", text).strip()\n",
    "    return text\n",
    "\n",
    "def parse_url_list(cell: str) -> List[str]:\n",
    "    \"\"\"Split the images cell into a de-duplicated, ordered list of URLs.\"\"\"\n",
    "    if not cell:\n",
    "        return []\n",
    "    parts = [p.strip() for p in cell.split(\",\")]\n",
    "    seen = set()\n",
    "    out: List[str] = []\n",
    "    for p in parts:\n",
    "        if not p or not p.startswith(\"http\"):\n",
    "            continue\n",
    "        if p not in seen:\n",
    "            seen.add(p)\n",
    "            out.append(p)\n",
    "    return out\n",
    "\n",
    "def url_hash(url: str, n: int = 16) -> str:\n",
    "    \"\"\"Stable short id for an image based on its URL.\"\"\"\n",
    "    return hashlib.sha256(url.encode(\"utf-8\")).hexdigest()[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d15a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "CONTEXT_FIELDS = [\n",
    "    \"context_id\",\"date\",\"name\",\"description\",\"latitude\",\"longitude\",\n",
    "    \"type_code\",\"category\",\"minimum period\",\"maximum period\",\n",
    "    \"creator\",\"reviewer\",\"reviewer_notes_text\"\n",
    "]\n",
    "IMAGES_FIELDS = [\"image_id\",\"context_id\",\"image_index\",\"image_url\"]\n",
    "\n",
    "def split_oervondstchecker(input_path: str,\n",
    "                           context_out: str = \"oervondstchecker_context.csv\",\n",
    "                           images_out: str = \"oervondstchecker_images.csv\") -> None:\n",
    "    \"\"\"Split the export into two CSVs (context + images).\"\"\"\n",
    "    path = Path(input_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {path}\")\n",
    "    sample = path.read_text(encoding=\"utf-8\", errors=\"ignore\")[:4096]\n",
    "    delim = sniff_delimiter(sample)\n",
    "\n",
    "    # Read robustly with DictReader\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=delim, quotechar='\"')\n",
    "        for r in reader:\n",
    "            rows.append(r)\n",
    "\n",
    "    # Build outputs\n",
    "    ctx_records = []\n",
    "    img_records = []\n",
    "    context_id = 0\n",
    "    for r in rows:\n",
    "        context_id += 1\n",
    "        ctx_records.append({\n",
    "            \"context_id\": context_id,\n",
    "            \"date\": r.get(\"date\",\"\"),\n",
    "            \"name\": r.get(\"name\",\"\"),\n",
    "            \"description\": r.get(\"description\",\"\"),\n",
    "            \"latitude\": r.get(\"latitude\",\"\"),\n",
    "            \"longitude\": r.get(\"longitude\",\"\"),\n",
    "            \"type_code\": r.get(\"type_code\",\"\"),\n",
    "            \"category\": r.get(\"category\",\"\"),\n",
    "            \"minimum period\": r.get(\"minimum period\",\"\"),\n",
    "            \"maximum period\": r.get(\"maximum period\",\"\"),\n",
    "            \"creator\": r.get(\"creator\",\"\"),\n",
    "            \"reviewer\": r.get(\"reviewer\",\"\"),\n",
    "            \"reviewer_notes_text\": html_to_text(r.get(\"reviewer_notes\",\"\")),\n",
    "        })\n",
    "        urls = parse_url_list(r.get(\"images\",\"\"))\n",
    "        seen = set()\n",
    "        idx = 0\n",
    "        for u in urls:\n",
    "            if u in seen:\n",
    "                continue\n",
    "            seen.add(u)\n",
    "            idx += 1\n",
    "            img_records.append({\n",
    "                \"image_id\": url_hash(u),\n",
    "                \"context_id\": context_id,\n",
    "                \"image_index\": idx,\n",
    "                \"image_url\": u,\n",
    "            })\n",
    "\n",
    "    # Write CSVs\n",
    "    df_ctx = pd.DataFrame(ctx_records, columns=CONTEXT_FIELDS)\n",
    "    df_img = pd.DataFrame(img_records, columns=IMAGES_FIELDS)\n",
    "    df_ctx.to_csv(context_out, index=False)\n",
    "    df_img.to_csv(images_out, index=False)\n",
    "    print(f\"Wrote {context_out} ({len(df_ctx)} rows)\")\n",
    "    print(f\"Wrote {images_out} ({len(df_img)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2461bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Parameters ====\n",
    "INPUT_PATH = \"2023-01-13Data-exportOervondstchecker.csv\" \n",
    "CONTEXT_OUT = \"oervondstchecker_context.csv\"\n",
    "IMAGES_OUT = \"oervondstchecker_images.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2213c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 922: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the split (make sure INPUT_PATH is correct)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43msplit_oervondstchecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONTEXT_OUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMAGES_OUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36msplit_oervondstchecker\u001b[0;34m(input_path, context_out, images_out)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m path\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     23\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(f, delimiter\u001b[38;5;241m=\u001b[39mdelim, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     25\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Build outputs\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fruit/lib/python3.10/csv.py:110\u001b[0m, in \u001b[0;36mDictReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# Used only for its side effect.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfieldnames\u001b[49m\n\u001b[1;32m    111\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mline_num\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fruit/lib/python3.10/csv.py:97\u001b[0m, in \u001b[0;36mDictReader.fieldnames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fieldnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fieldnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fruit/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 922: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the split (make sure INPUT_PATH is correct)\n",
    "try:\n",
    "    split_oervondstchecker(INPUT_PATH, CONTEXT_OUT, IMAGES_OUT)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    print(\"Place your export next to this notebook or update INPUT_PATH above.\")\n",
    "\n",
    "# Optional: Preview heads if files exist\n",
    "try:\n",
    "    import pandas as pd\n",
    "    display(pd.read_csv(CONTEXT_OUT).head())\n",
    "    display(pd.read_csv(IMAGES_OUT).head())\n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fruit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
